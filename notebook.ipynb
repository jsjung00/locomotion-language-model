{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small-LLM (Locomotion Language Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Can textual language models understand / reason about physics and locomotion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animals have knowledge regarding physics and locomotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"media/leg-giraffe.gif\" alt=\"Giraffe walking\" style=\"max-width: 45%; height: auto;\">\n",
    "    <p>Giraffe walking</p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"media/half_cheetah.png\" alt=\"Cheetah\" style=\"max-width: 45%; height: auto;\">\n",
    "    <p>RL Gym Cheetah</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) RAG In Context Learning + Closed Loop Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt: You are an expert Mujoco Half Cheetah V0 environment controller.\n",
    "\n",
    "```\n",
    "Dynamic Prompt: \n",
    "\"Time step {t}. HalfCheetah-v0 state vector has dimension 17. \n",
    "Current state: {state_list}.\n",
    "Here are similar states to the current state and their corresonding actions to take you should use as a reference:\n",
    "Similar state: {near_state} : action {near_action}...\n",
    "\n",
    "Respond in strict JSON: {\\\"action\\\": [f1, f2, f3, f4, f5, f6]}. No extra text.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"media/closed_loop.png\" alt=\"Closed Loop\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40/40\n",
      "Current state: [ -0.189   3.261  -0.334   0.322   0.167  -0.483  -0.105   0.186   1.081\n",
      "  -2.492   6.21   -8.33   -5.76  -10.103  -0.018 -10.015   2.661]\n",
      "GPT generated action: [ 0.644  0.527 -0.183 -0.775 -0.737  0.712]\n",
      "\n",
      "<<< Saved video to /home/ubuntu/small-llm/test-decision-transformer/saved_vids/ragwrapper_cheetah_99059.mp4 >>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gpt_wrapper.rag import rag_with_gpt\n",
    "from visualize import replay_offscreen\n",
    "import os \n",
    "import random \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# generate some trajectories\n",
    "np_actions = rag_with_gpt(max_steps=40)\n",
    "\n",
    "# visualize as video\n",
    "replay_offscreen('mujoco/halfcheetah/expert-v0', np_actions, out_path=os.path.join(\"/home/ubuntu/small-llm/test-decision-transformer/saved_vids\", f\"ragwrapper_cheetah_{random.randint(0,100000)}.mp4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around; align-items: flex-start; flex-wrap: nowrap; overflow-x: auto;\">\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"saved_vids/ragwrapper_cheetah_35441.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"saved_vids/ragwrapper_cheetah_55262.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"saved_vids/ragwrapper_cheetah_99059.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Fine-tuned small LLM (Pythia-410M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We freeze the entire model and only train linear encoder and decoder layers (4M trainable params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"media/pythia_finetune.png\" alt=\"Closed Loop\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<< Saved video to /home/ubuntu/small-llm/test-decision-transformer/saved_vids/pythia_targetreward_300_cheetah_20298.mp4 >>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from visualize import viz_driver\n",
    "\n",
    "# Note: we can condition on our target reward \n",
    "viz_driver(\"pythia\", target_rew=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo videos with different reward conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around; align-items: flex-start; flex-wrap: nowrap; overflow-x: auto;\">\n",
    "  <div style=\"text-align: center; min-width: 300px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 600</h4>\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/pythia_targetreward_600_cheetah_81075.mp4\" type=\"video/mp4\"> \n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"text-align: center; min-width: 300px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 1200</h4>\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/pythia_targetreward_1200_cheetah_68985.mp4\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"text-align: center; min-width: 300px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 2400</h4>\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/pythia_targetreward_2400_cheetah_31850.mp4\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Train GPT2 from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following *Decision Transformer (Chen et al. 2021)*, train GPT2 decoder model (700K params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"media/decision_transformer.png\" alt=\"Closed Loop\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<< Saved video to /home/ubuntu/small-llm/test-decision-transformer/saved_vids/dt_targetreward_300_cheetah_18256.mp4 >>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from visualize import viz_driver\n",
    "\n",
    "# Note: we can condition on our target reward \n",
    "viz_driver(\"dt\", target_rew=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo videos with different reward conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around; align-items: flex-start; flex-wrap: nowrap; overflow-x: auto;\">\n",
    "  <div style=\"text-align: center; min-width: 320px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 300</h4>\n",
    "      <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/dt_targetreward_300_cheetah_56626.mp4\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"text-align: center; min-width: 320px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 600</h4>\n",
    "      <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/dt_targetreward_600_cheetah_58199.mp4\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"text-align: center; min-width: 320px; margin: 0 10px;\">\n",
    "    <h4>Reward Target: 1200</h4>\n",
    "      <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"saved_vids/dt_targetreward_1200_cheetah_44888.mp4\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison on fine-tuned frozen LLM with GPT trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Model comparison](media/model_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"media/leg-giraffe.gif\" alt=\"Giraffe walking\" style=\"max-width: 45%; height: auto;\">\n",
    "    <p>Giraffe walking</p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"media/dt_cheetah_1-3s.gif\" alt=\"Cheetah\" style=\"max-width: 45%; height: auto;\">\n",
    "    <p>RL Gym Cheetah</p>\n",
    "  </div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
